{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 6344972,
          "sourceType": "datasetVersion",
          "datasetId": 3653411
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "FINETUNEDPUNJABI",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nayani-j/OpenAI-whisper-small---Punjabi/blob/main/FINETUNEDPUNJABI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-23T14:57:00.253858Z",
          "iopub.execute_input": "2024-05-23T14:57:00.254757Z",
          "iopub.status.idle": "2024-05-23T14:57:00.665158Z",
          "shell.execute_reply.started": "2024-05-23T14:57:00.254724Z",
          "shell.execute_reply": "2024-05-23T14:57:00.664134Z"
        },
        "trusted": true,
        "id": "YRXnWweuccaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T14:57:05.693573Z",
          "iopub.execute_input": "2024-05-23T14:57:05.694145Z",
          "iopub.status.idle": "2024-05-23T14:58:20.240972Z",
          "shell.execute_reply.started": "2024-05-23T14:57:05.694103Z",
          "shell.execute_reply": "2024-05-23T14:58:20.239624Z"
        },
        "trusted": true,
        "id": "zjyPTpanccaf",
        "outputId": "586a3ba8-3aa1-4c90-f7a6-5afed0acfcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.0\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\nCollecting transformers\n  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.29.3)\nCollecting accelerate\n  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nCollecting jiwer\n  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\nCollecting tensorboard\n  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\nCollecting gradio\n  Downloading gradio-4.31.5-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: datasets[audio] in /opt/conda/lib/python3.10/site-packages (2.18.0)\nCollecting datasets[audio]\n  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets[audio]) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (6.0.1)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.12.1)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.10.1)\nCollecting huggingface-hub>=0.21.2 (from datasets[audio])\n  Downloading huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nCollecting tokenizers<0.20,>=0.19 (from transformers)\n  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\nCollecting rapidfuzz<4,>=3 (from jiwer)\n  Downloading rapidfuzz-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.51.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.2)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (5.3.0)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio) (0.108.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting gradio-client==0.16.4 (from gradio)\n  Downloading gradio_client-0.16.4-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.1.1)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.2)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.3)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.5)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.9.10)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (9.5.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.5.3)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.9 (from gradio)\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.4.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit==0.12.0 (from gradio)\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nCollecting typer<1.0,>=0.12 (from gradio)\n  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.9.0)\nCollecting urllib3~=2.0 (from gradio)\n  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.0)\nCollecting websockets<12.0,>=10.0 (from gradio-client==0.16.4->gradio)\n  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.20.0)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (4.0.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2023.4)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets[audio]) (3.3.2)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.0)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio) (0.32.0.post1)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.11.4)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.4.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.58.1)\nRequirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.8.1)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.3.7)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.3)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.0.7)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.41.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.0->librosa->datasets[audio]) (4.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.2.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\nDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio-4.31.5-py3-none-any.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading gradio_client-0.16.4-py3-none-any.whl (315 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading datasets-2.19.1-py3-none-any.whl (542 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading rapidfuzz-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading ruff-0.4.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ffmpy\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=41d38b07d29c761e53700ef9103c2397bcea7dc11f32e20b9c398775031c717c\n  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\nSuccessfully built ffmpy\nInstalling collected packages: ffmpy, websockets, urllib3, tomlkit, semantic-version, ruff, rapidfuzz, python-multipart, tensorboard, jiwer, typer, huggingface-hub, tokenizers, gradio-client, datasets, accelerate, transformers, gradio, evaluate\n  Attempting uninstall: websockets\n    Found existing installation: websockets 12.0\n    Uninstalling websockets-12.0:\n      Successfully uninstalled websockets-12.0\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.12.4\n    Uninstalling tomlkit-0.12.4:\n      Successfully uninstalled tomlkit-0.12.4\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.15.1\n    Uninstalling tensorboard-2.15.1:\n      Successfully uninstalled tensorboard-2.15.1\n  Attempting uninstall: typer\n    Found existing installation: typer 0.9.0\n    Uninstalling typer-0.9.0:\n      Successfully uninstalled typer-0.9.0\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.22.2\n    Uninstalling huggingface-hub-0.22.2:\n      Successfully uninstalled huggingface-hub-0.22.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.18.0\n    Uninstalling datasets-2.18.0:\n      Successfully uninstalled datasets-2.18.0\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.29.3\n    Uninstalling accelerate-0.29.3:\n      Successfully uninstalled accelerate-0.29.3\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.39.3\n    Uninstalling transformers-4.39.3:\n      Successfully uninstalled transformers-4.39.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.1 which is incompatible.\nspacy 3.7.3 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.2.1 which is incompatible.\ntensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.16.2 which is incompatible.\nweasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-0.30.1 datasets-2.19.1 evaluate-0.4.2 ffmpy-0.3.2 gradio-4.31.5 gradio-client-0.16.4 huggingface-hub-0.23.1 jiwer-3.0.4 python-multipart-0.0.9 rapidfuzz-3.9.1 ruff-0.4.5 semantic-version-2.10.0 tensorboard-2.16.2 tokenizers-0.19.1 tomlkit-0.12.0 transformers-4.41.1 typer-0.12.3 urllib3-2.1.0 websockets-11.0.3\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T14:59:58.702617Z",
          "iopub.execute_input": "2024-05-23T14:59:58.703371Z",
          "iopub.status.idle": "2024-05-23T14:59:59.009953Z",
          "shell.execute_reply.started": "2024-05-23T14:59:58.703332Z",
          "shell.execute_reply": "2024-05-23T14:59:59.008969Z"
        },
        "trusted": true,
        "id": "HUinR8aeccag",
        "outputId": "5f11cce2-37ec-4d0d-be2f-dde6601f598d",
        "colab": {
          "referenced_widgets": [
            "34aa6c64d445420597fafe7a729fd8c5"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34aa6c64d445420597fafe7a729fd8c5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice = DatasetDict()\n",
        "\n",
        "common_voice[\"train\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"pa-IN\", split=\"train+validation\", use_auth_token=True,trust_remote_code=True)\n",
        "common_voice[\"test\"] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"pa-IN\", split=\"test\", use_auth_token=True,trust_remote_code=True)\n",
        "\n",
        "print(common_voice)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:00:31.53767Z",
          "iopub.execute_input": "2024-05-23T15:00:31.538111Z",
          "iopub.status.idle": "2024-05-23T15:00:46.28869Z",
          "shell.execute_reply.started": "2024-05-23T15:00:31.538077Z",
          "shell.execute_reply": "2024-05-23T15:00:46.287434Z"
        },
        "trusted": true,
        "id": "7KKeiO0dccag",
        "outputId": "449eefaf-2c67-4d01-9247-eb87b298ae25",
        "colab": {
          "referenced_widgets": [
            "38010fafc7ab48f1b532a05645da88fe",
            "7a5a3d435c3441acae38d62a5ddf8790",
            "e288b258985148eba7e7b452ebee004a",
            "d5f079a3df78430abf5c0e6b6153503f",
            "6b8596bae061404f9c007d4fc1debda4",
            "e72f80f61386432085be066f86e2b3a5",
            "f4af745379d84067bc5591a08bf794f5",
            "ca0827d9f89b4281b3ec8154ca27869c",
            "34d33ed98b834822a5dbe2877e2a8b8d",
            "3254bd4ebecf47aba4ab6ec79370fb72",
            "61dc2702490845afab507e281f4b5705",
            "ff9519e13de3463bbee5b94838f00c97",
            "922701728cb049feb4b347f471f8f083",
            "632f03302bda421eb41b5e7749a271df",
            "3e237cfa10cb4027854a42b8ebc52ac8",
            "1d395606f8c94c588ee8f9818fc59f38",
            "ed9a31e8849e4290a79a2b5fcfdd3ca0",
            "7dd5635df7bc42fcb632e1f529946d8a",
            "92148db62e544b5a8d3744bfb804270d",
            "3582dee258474b338085b84eb8a06445"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\nYou can remove this warning by passing 'token=<use_auth_token>' instead.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/8.13k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38010fafc7ab48f1b532a05645da88fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading readme:   0%|          | 0.00/14.4k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a5a3d435c3441acae38d62a5ddf8790"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading extra modules:   0%|          | 0.00/3.44k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e288b258985148eba7e7b452ebee004a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading extra modules:   0%|          | 0.00/60.9k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5f079a3df78430abf5c0e6b6153503f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/12.2k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b8596bae061404f9c007d4fc1debda4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/29.5M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e72f80f61386432085be066f86e2b3a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/9.70M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4af745379d84067bc5591a08bf794f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/14.8M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca0827d9f89b4281b3ec8154ca27869c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/42.1M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34d33ed98b834822a5dbe2877e2a8b8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/2.86M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3254bd4ebecf47aba4ab6ec79370fb72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/188k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61dc2702490845afab507e281f4b5705"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/77.0k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff9519e13de3463bbee5b94838f00c97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/107k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "922701728cb049feb4b347f471f8f083"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/345k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "632f03302bda421eb41b5e7749a271df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/20.5k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e237cfa10cb4027854a42b8ebc52ac8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d395606f8c94c588ee8f9818fc59f38"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nReading metadata...: 685it [00:00, 56759.28it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating validation split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed9a31e8849e4290a79a2b5fcfdd3ca0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nReading metadata...: 280it [00:00, 57402.86it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating test split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7dd5635df7bc42fcb632e1f529946d8a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nReading metadata...: 399it [00:00, 54476.80it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating other split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92148db62e544b5a8d3744bfb804270d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nReading metadata...: 1285it [00:00, 83463.89it/s]\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating invalidated split: 0 examples [00:00, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3582dee258474b338085b84eb8a06445"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "\nReading metadata...: 75it [00:00, 56977.50it/s]\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\nYou can remove this warning by passing 'token=<use_auth_token>' instead.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "DatasetDict({\n    train: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n        num_rows: 965\n    })\n    test: Dataset({\n        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n        num_rows: 399\n    })\n})\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice = common_voice.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:01:54.878756Z",
          "iopub.execute_input": "2024-05-23T15:01:54.879475Z",
          "iopub.status.idle": "2024-05-23T15:01:54.892108Z",
          "shell.execute_reply.started": "2024-05-23T15:01:54.879441Z",
          "shell.execute_reply": "2024-05-23T15:01:54.891264Z"
        },
        "trusted": true,
        "id": "CUCOhmkGccag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:02:44.837542Z",
          "iopub.execute_input": "2024-05-23T15:02:44.837939Z",
          "iopub.status.idle": "2024-05-23T15:02:48.709376Z",
          "shell.execute_reply.started": "2024-05-23T15:02:44.837909Z",
          "shell.execute_reply": "2024-05-23T15:02:48.708213Z"
        },
        "trusted": true,
        "id": "SEOr67kzccah",
        "outputId": "5b42fe92-a928-4acc-cd5f-bd2c280e8cdd",
        "colab": {
          "referenced_widgets": [
            "c80d83d226b548feae2f331850278b87"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c80d83d226b548feae2f331850278b87"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Punjabi\", task=\"translate\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:04:58.723758Z",
          "iopub.execute_input": "2024-05-23T15:04:58.72501Z",
          "iopub.status.idle": "2024-05-23T15:04:59.904816Z",
          "shell.execute_reply.started": "2024-05-23T15:04:58.724941Z",
          "shell.execute_reply": "2024-05-23T15:04:59.903835Z"
        },
        "trusted": true,
        "id": "hKj0ypGwccah",
        "outputId": "54ce7c03-4ea0-4600-ae9c-6665d1d6a4d7",
        "colab": {
          "referenced_widgets": [
            "7b3d66b55d0e4947bd18bfd65f5e423a",
            "f1d9ca65c50149cebcfc992e7428786f",
            "94654e412b984da7995c2df81e0ae714",
            "59fb8f4150ad4e5cbc249e52024a1b34",
            "74233b5a8bde4e709e2e26dbbed8d1fa",
            "5b189e2a7bca46b7b73f0f6310f71823",
            "7aa945411a2f42f8bb973b8a5093ace0"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b3d66b55d0e4947bd18bfd65f5e423a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1d9ca65c50149cebcfc992e7428786f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94654e412b984da7995c2df81e0ae714"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59fb8f4150ad4e5cbc249e52024a1b34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74233b5a8bde4e709e2e26dbbed8d1fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b189e2a7bca46b7b73f0f6310f71823"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7aa945411a2f42f8bb973b8a5093ace0"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifying tokenizer encoding\n",
        "\n",
        "input_str = common_voice[\"train\"][0][\"sentence\"]\n",
        "labels = tokenizer(input_str).input_ids\n",
        "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
        "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
        "\n",
        "print(f\"Input:                 {input_str}\")\n",
        "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
        "print(f\"Decoded w/out special: {decoded_str}\")\n",
        "print(f\"Are equal:             {input_str == decoded_str}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:05:18.521061Z",
          "iopub.execute_input": "2024-05-23T15:05:18.522233Z",
          "iopub.status.idle": "2024-05-23T15:05:40.859498Z",
          "shell.execute_reply.started": "2024-05-23T15:05:18.52219Z",
          "shell.execute_reply": "2024-05-23T15:05:40.8584Z"
        },
        "trusted": true,
        "id": "DuxGoyGXccah",
        "outputId": "451d53a0-7afb-4c0f-e8af-cb0a151b6103"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-05-23 15:05:30.380091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-23 15:05:30.380232: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-23 15:05:30.522662: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Input:                 ਕਲੱਬਾਂ ਦੇ ਬੈਨਰ ਲੱਗੇ ਹੋਏ ਸਨ\nDecoded w/ special:    <|startoftranscript|><|pa|><|translate|><|notimestamps|>ਕਲੱਬਾਂ ਦੇ ਬੈਨਰ ਲੱਗੇ ਹੋਏ ਸਨ<|endoftext|>\nDecoded w/out special: ਕਲੱਬਾਂ ਦੇ ਬੈਨਰ ਲੱਗੇ ਹੋਏ ਸਨ\nAre equal:             True\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine to create a WhisperProcessor\n",
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Punjabi\", task=\"translate\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:06:37.719256Z",
          "iopub.execute_input": "2024-05-23T15:06:37.720086Z",
          "iopub.status.idle": "2024-05-23T15:06:38.678591Z",
          "shell.execute_reply.started": "2024-05-23T15:06:37.720049Z",
          "shell.execute_reply": "2024-05-23T15:06:38.677717Z"
        },
        "trusted": true,
        "id": "I7JDO7CJccah",
        "outputId": "c457ded8-6d18-4c31-91be-cebf22ebe3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print first example of common voice\n",
        "print(common_voice[\"train\"][0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:06:54.602881Z",
          "iopub.execute_input": "2024-05-23T15:06:54.603311Z",
          "iopub.status.idle": "2024-05-23T15:06:54.618135Z",
          "shell.execute_reply.started": "2024-05-23T15:06:54.603276Z",
          "shell.execute_reply": "2024-05-23T15:06:54.616981Z"
        },
        "trusted": true,
        "id": "zFoZyHu7ccai",
        "outputId": "2647cac4-8445-4735-fe59-d4283a057417"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/c015d2766ea512358e1fa9ad11a6eea73273b6851ab4f6d1d680587764e9f585/pa-IN_train_0/common_voice_pa-IN_23337849.mp3', 'array': array([0., 0., 0., ..., 0., 0., 0.]), 'sampling_rate': 48000}, 'sentence': 'ਕਲੱਬਾਂ ਦੇ ਬੈਨਰ ਲੱਗੇ ਹੋਏ ਸਨ'}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "from datasets import Audio\n",
        "\n",
        "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:07:16.795706Z",
          "iopub.execute_input": "2024-05-23T15:07:16.796126Z",
          "iopub.status.idle": "2024-05-23T15:07:16.812581Z",
          "shell.execute_reply.started": "2024-05-23T15:07:16.796092Z",
          "shell.execute_reply": "2024-05-23T15:07:16.811246Z"
        },
        "trusted": true,
        "id": "R1ckLkRGccai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(common_voice[\"train\"][0])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:07:32.115105Z",
          "iopub.execute_input": "2024-05-23T15:07:32.115494Z",
          "iopub.status.idle": "2024-05-23T15:07:32.135418Z",
          "shell.execute_reply.started": "2024-05-23T15:07:32.115465Z",
          "shell.execute_reply": "2024-05-23T15:07:32.134178Z"
        },
        "trusted": true,
        "id": "xrTM2rxbccai",
        "outputId": "e1af27a4-e4eb-452e-ca6e-ce54485a395a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/c015d2766ea512358e1fa9ad11a6eea73273b6851ab4f6d1d680587764e9f585/pa-IN_train_0/common_voice_pa-IN_23337849.mp3', 'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n        1.57673874e-12, -5.00932629e-13, -3.45390383e-13]), 'sampling_rate': 16000}, 'sentence': 'ਕਲੱਬਾਂ ਦੇ ਬੈਨਰ ਲੱਗੇ ਹੋਏ ਸਨ'}\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(batch):\n",
        "    # load and resample audio data from 48 to 16kHz\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # compute log-Mel input features from input audio array\n",
        "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    # encode target text to label ids\n",
        "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:07:54.581168Z",
          "iopub.execute_input": "2024-05-23T15:07:54.581603Z",
          "iopub.status.idle": "2024-05-23T15:07:54.588219Z",
          "shell.execute_reply.started": "2024-05-23T15:07:54.581568Z",
          "shell.execute_reply": "2024-05-23T15:07:54.586908Z"
        },
        "trusted": true,
        "id": "1jZB6Q4uccai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:08:12.904247Z",
          "iopub.execute_input": "2024-05-23T15:08:12.905064Z",
          "iopub.status.idle": "2024-05-23T15:09:02.388302Z",
          "shell.execute_reply.started": "2024-05-23T15:08:12.905031Z",
          "shell.execute_reply": "2024-05-23T15:09:02.386973Z"
        },
        "trusted": true,
        "id": "j5Y-11FVccai",
        "outputId": "f5e3c223-051f-49d7-cf9d-a17c098c216a",
        "colab": {
          "referenced_widgets": [
            "7c01bef48d8e4e36951d07dde3fd4359",
            "d9228a0fb0824eb3ba6de211cd89555e"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/965 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c01bef48d8e4e36951d07dde3fd4359"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map (num_proc=4):   0%|          | 0/399 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9228a0fb0824eb3ba6de211cd89555e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperForConditionalGeneration\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:13:46.557209Z",
          "iopub.execute_input": "2024-05-23T15:13:46.557646Z",
          "iopub.status.idle": "2024-05-23T15:13:53.823328Z",
          "shell.execute_reply.started": "2024-05-23T15:13:46.557611Z",
          "shell.execute_reply": "2024-05-23T15:13:53.822055Z"
        },
        "trusted": true,
        "id": "CMLWHEWHccai",
        "outputId": "64adc03a-3135-49f2-f1a0-9a0aafb26af2",
        "colab": {
          "referenced_widgets": [
            "2f9eb97e90a84458924b51fefd659548",
            "0e50271a12e6420bafa85f54bb8b7aa1",
            "17556619d1b44ab98d30777832ec1bd1"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f9eb97e90a84458924b51fefd659548"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e50271a12e6420bafa85f54bb8b7aa1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17556619d1b44ab98d30777832ec1bd1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.generation_config.language = \"punjabi\"\n",
        "model.generation_config.task = \"translate\"\n",
        "\n",
        "model.generation_config.forced_decoder_ids = None"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:14:51.333505Z",
          "iopub.execute_input": "2024-05-23T15:14:51.333908Z",
          "iopub.status.idle": "2024-05-23T15:14:51.340395Z",
          "shell.execute_reply.started": "2024-05-23T15:14:51.333875Z",
          "shell.execute_reply": "2024-05-23T15:14:51.339154Z"
        },
        "trusted": true,
        "id": "PuHKAOxVccai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "    decoder_start_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:15:31.495577Z",
          "iopub.execute_input": "2024-05-23T15:15:31.496052Z",
          "iopub.status.idle": "2024-05-23T15:15:31.507937Z",
          "shell.execute_reply.started": "2024-05-23T15:15:31.496017Z",
          "shell.execute_reply": "2024-05-23T15:15:31.50681Z"
        },
        "trusted": true,
        "id": "xY4Et9kbccai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
        "    processor=processor,\n",
        "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:15:56.545992Z",
          "iopub.execute_input": "2024-05-23T15:15:56.546405Z",
          "iopub.status.idle": "2024-05-23T15:15:56.551755Z",
          "shell.execute_reply.started": "2024-05-23T15:15:56.546371Z",
          "shell.execute_reply": "2024-05-23T15:15:56.550667Z"
        },
        "trusted": true,
        "id": "Lb1DIr7xccaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"wer\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:16:26.745005Z",
          "iopub.execute_input": "2024-05-23T15:16:26.745416Z",
          "iopub.status.idle": "2024-05-23T15:16:27.450855Z",
          "shell.execute_reply.started": "2024-05-23T15:16:26.745381Z",
          "shell.execute_reply": "2024-05-23T15:16:27.449665Z"
        },
        "trusted": true,
        "id": "8y2eHu0Iccaj",
        "outputId": "920ed227-a022-4119-9326-3ee9b8f6bc86",
        "colab": {
          "referenced_widgets": [
            "037d2a9f608545cb97efab1a5438db9d"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "037d2a9f608545cb97efab1a5438db9d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:16:49.891372Z",
          "iopub.execute_input": "2024-05-23T15:16:49.892332Z",
          "iopub.status.idle": "2024-05-23T15:16:49.899012Z",
          "shell.execute_reply.started": "2024-05-23T15:16:49.892298Z",
          "shell.execute_reply": "2024-05-23T15:16:49.897787Z"
        },
        "trusted": true,
        "id": "8IhW9gmoccaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-small-punjabi\",  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=1000,\n",
        "    gradient_checkpointing=True,\n",
        "    fp16=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=8,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=1000,\n",
        "    eval_steps=1000,\n",
        "    logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:17:32.267708Z",
          "iopub.execute_input": "2024-05-23T15:17:32.268117Z",
          "iopub.status.idle": "2024-05-23T15:17:32.364309Z",
          "shell.execute_reply.started": "2024-05-23T15:17:32.268087Z",
          "shell.execute_reply": "2024-05-23T15:17:32.363223Z"
        },
        "trusted": true,
        "id": "O6figTQpccaj",
        "outputId": "54663ed1-3dc7-494b-8fa0-6f64fa90ad1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=common_voice[\"train\"],\n",
        "    eval_dataset=common_voice[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:17:50.686589Z",
          "iopub.execute_input": "2024-05-23T15:17:50.687008Z",
          "iopub.status.idle": "2024-05-23T15:17:51.446573Z",
          "shell.execute_reply.started": "2024-05-23T15:17:50.686973Z",
          "shell.execute_reply": "2024-05-23T15:17:51.445497Z"
        },
        "trusted": true,
        "id": "5lRK-SPDccaj",
        "outputId": "f0627836-c00e-4ed9-db69-3cbc146c1d04"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "max_steps is given, it will override any value given in num_train_epochs\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T15:18:17.189808Z",
          "iopub.execute_input": "2024-05-23T15:18:17.190641Z",
          "iopub.status.idle": "2024-05-23T17:38:50.506812Z",
          "shell.execute_reply.started": "2024-05-23T15:18:17.190605Z",
          "shell.execute_reply": "2024-05-23T17:38:50.505557Z"
        },
        "trusted": true,
        "id": "WoWvLP52ccaj",
        "outputId": "26228e3f-a275-4702-f9e8-1b2bbf5977bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1000/1000 2:19:52, Epoch 16/17]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1000</td>\n      <td>0.000300</td>\n      <td>0.478935</td>\n      <td>49.858757</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\nThere were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
          "output_type": "stream"
        },
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=1000, training_loss=0.2855087027698755, metrics={'train_runtime': 8404.8634, 'train_samples_per_second': 1.904, 'train_steps_per_second': 0.119, 'total_flos': 4.56657537466368e+18, 'train_loss': 0.2855087027698755, 'epoch': 16.39344262295082})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\n",
        "    \"dataset\": \"Common Voice 11.0\",  # a 'pretty' name for the training dataset\n",
        "    \"dataset_args\": \"config: mr, split: test\",\n",
        "    \"language\": \"pa\",\n",
        "    \"model_name\": \"Whisper Small Punjabi - Nayani Jindal\",  # a 'pretty' name for your model\n",
        "    \"finetuned_from\": \"openai/whisper-small\",\n",
        "    \"tasks\": \"automatic-speech-recognition\",\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T17:45:46.282501Z",
          "iopub.execute_input": "2024-05-23T17:45:46.283376Z",
          "iopub.status.idle": "2024-05-23T17:45:46.289013Z",
          "shell.execute_reply.started": "2024-05-23T17:45:46.283338Z",
          "shell.execute_reply": "2024-05-23T17:45:46.287736Z"
        },
        "trusted": true,
        "id": "j5sb_nNlccaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(**kwargs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T17:46:05.38855Z",
          "iopub.execute_input": "2024-05-23T17:46:05.389667Z",
          "iopub.status.idle": "2024-05-23T17:46:11.798009Z",
          "shell.execute_reply.started": "2024-05-23T17:46:05.389612Z",
          "shell.execute_reply": "2024-05-23T17:46:11.796631Z"
        },
        "trusted": true,
        "id": "MAGsEOWyccaj",
        "outputId": "0124252e-2305-43aa-f061-0128c31ed842"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}\n",
          "output_type": "stream"
        },
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/nayaniiii/whisper-small-punjabi/commit/4dfdffa528215fca5eedd07b6e64a21c7f188ada', commit_message='End of training', commit_description='', oid='4dfdffa528215fca5eedd07b6e64a21c7f188ada', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub(\"nayaniiii/whisper-small-punjabi\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T17:47:47.911414Z",
          "iopub.execute_input": "2024-05-23T17:47:47.912202Z",
          "iopub.status.idle": "2024-05-23T17:47:49.536565Z",
          "shell.execute_reply.started": "2024-05-23T17:47:47.912163Z",
          "shell.execute_reply": "2024-05-23T17:47:49.535446Z"
        },
        "trusted": true,
        "id": "9anEEwc7ccaj",
        "outputId": "7b7e924a-0260-4885-c427-4321624e8aac",
        "colab": {
          "referenced_widgets": [
            "4d7d00ef84804ae189b77e9ff5baf544"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/1.88k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d7d00ef84804ae189b77e9ff5baf544"
            }
          },
          "metadata": {}
        },
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CommitInfo(commit_url='https://huggingface.co/nayaniiii/whisper-small-punjabi/commit/e1448ddae1a90370bdbf24b35394f185cf5a7074', commit_message='Upload tokenizer', commit_description='', oid='e1448ddae1a90370bdbf24b35394f185cf5a7074', pr_url=None, pr_revision=None, pr_num=None)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"nayaniiii/whisper-small-punjabi\")\n",
        "processor = WhisperProcessor.from_pretrained(\"nayaniiii/whisper-small-punjabi\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T17:48:31.617596Z",
          "iopub.execute_input": "2024-05-23T17:48:31.618033Z",
          "iopub.status.idle": "2024-05-23T17:48:52.138042Z",
          "shell.execute_reply.started": "2024-05-23T17:48:31.618Z",
          "shell.execute_reply": "2024-05-23T17:48:52.136878Z"
        },
        "trusted": true,
        "id": "fYhxBsg1ccaj",
        "outputId": "8309b9da-0d3b-48bc-fa1a-63b0455da46b",
        "colab": {
          "referenced_widgets": [
            "f3aecfcf02c94a3986e2da2606ab1bca",
            "fee65229600244e8a5f7f69998405dca",
            "515885f2a3064489bec76f8042bd41e9",
            "58a98c4f9dd54ee1bc529f3260a2dca8",
            "36c830b511584c40990d1b31498256ae",
            "085695a8faa549e194199bf13b5f1f3c",
            "2c1b9456ed0545c9809f4310af59ad61",
            "98475c3930c14581801a365df08fa132",
            "c68e2e991c1d4684bbe7c53a26e9d6de",
            "aef66c0fd2a24bb5a6b4ebd880865d10"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/2.25k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3aecfcf02c94a3986e2da2606ab1bca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fee65229600244e8a5f7f69998405dca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "generation_config.json:   0%|          | 0.00/3.81k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "515885f2a3064489bec76f8042bd41e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/339 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58a98c4f9dd54ee1bc529f3260a2dca8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36c830b511584c40990d1b31498256ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "085695a8faa549e194199bf13b5f1f3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c1b9456ed0545c9809f4310af59ad61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98475c3930c14581801a365df08fa132"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c68e2e991c1d4684bbe7c53a26e9d6de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aef66c0fd2a24bb5a6b4ebd880865d10"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline(model='nayaniiii/whisper-small-punjabi')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T17:53:15.755812Z",
          "iopub.execute_input": "2024-05-23T17:53:15.75626Z",
          "iopub.status.idle": "2024-05-23T17:53:17.481207Z",
          "shell.execute_reply.started": "2024-05-23T17:53:15.756229Z",
          "shell.execute_reply": "2024-05-23T17:53:17.480308Z"
        },
        "trusted": true,
        "id": "sNlyIJNwccaj",
        "outputId": "c022c4a2-f4ea-44b2-efcd-dd4eb22d3595"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(audio):\n",
        "    text = pipe(audio)[\"text\"]\n",
        "    return text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T17:53:39.137397Z",
          "iopub.execute_input": "2024-05-23T17:53:39.137767Z",
          "iopub.status.idle": "2024-05-23T17:53:39.142967Z",
          "shell.execute_reply.started": "2024-05-23T17:53:39.137739Z",
          "shell.execute_reply": "2024-05-23T17:53:39.141682Z"
        },
        "trusted": true,
        "id": "nTslOlBLccaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"/kaggle/input/punjabi-speech-recognition/punjabi/Audio files/Regional-Chandigarh-Punjabi-1820-20181010194756/sent_1.wav\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T18:07:19.512941Z",
          "iopub.execute_input": "2024-05-23T18:07:19.513419Z",
          "iopub.status.idle": "2024-05-23T18:07:35.344261Z",
          "shell.execute_reply.started": "2024-05-23T18:07:19.513386Z",
          "shell.execute_reply": "2024-05-23T18:07:35.343153Z"
        },
        "trusted": true,
        "id": "NJ8sSldKccaj",
        "outputId": "489db090-1fab-4511-aaae-008e02ee05c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'ਖ਼ੇਂਦਰੀ ਮੰਤਰੀਂ ਮੁਕਿਤਾ ਕਿਤਾ ਮੁਖਰੀ ਸਿੱਖਲਾਈ ਲਈ ਇਕਕਕੌਮੀਂ ਕੌਂਸਲ ਐਨਸੀ ਵੀ ਏਟੀ ਕਾਇਮਕਰਨਦਾ ਫੈਂਸਲਾ ਕੀਤੈ'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"/kaggle/input/punjabi-speech-recognition/punjabi/Audio files/Regional-Chandigarh-Punjabi-1820-20181010194756/sent_16.wav\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-23T18:09:33.175631Z",
          "iopub.execute_input": "2024-05-23T18:09:33.176092Z",
          "iopub.status.idle": "2024-05-23T18:09:57.140789Z",
          "shell.execute_reply.started": "2024-05-23T18:09:33.176059Z",
          "shell.execute_reply": "2024-05-23T18:09:57.139698Z"
        },
        "trusted": true,
        "id": "-DA9TJMKccaj",
        "outputId": "b10d3155-787c-454f-a061-a31f84100615"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'ਸੁਸ਼ਲਮੇਡੀਐ ਚੇ ਜਮੇਵਾਰੀਦੀ ਵਰਤੋਂ ਲਾਸਮੀ ਕਰਨਵਾਰੇ ਫੇਸਬੁੱਕੁਪਰ ਵਿਚਾਰਚਾਚਰ ਸਿਰਿਰ਼ੁਰ਼ ਠਾਉਡ ਨੇਕਿਆ ਕੇ ਮਾਪੇ ਤੇ ਦਿਆਪਕਰਸਾਂਗੀਆਂ ਕੂਸ਼ਾਂਨਾਂਹ ਇਸ ਪੱਸੇ ਵੱਡੀਪੂਮ ਕਨਵਾ ਸਕਤੇਰੁਵਾਂ'"
          },
          "metadata": {}
        }
      ]
    }
  ]
}